{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63b575c",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a298463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c79ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(data, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0941f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, color_path, gray_path, size=160):\n",
    "        self.size = size\n",
    "        self.color_path = color_path\n",
    "        self.gray_path = gray_path\n",
    "        self.color_images = self.load_images(color_path)\n",
    "        self.gray_images = self.load_images(gray_path)\n",
    "\n",
    "    def load_images(self, path):\n",
    "        images = []\n",
    "        files = sorted_alphanumeric(os.listdir(path))\n",
    "        for i in tqdm(files):\n",
    "            if i == '6000.jpg':\n",
    "                break\n",
    "            else:\n",
    "                img = Image.open(os.path.join(path, i)).convert('RGB')\n",
    "                img = img.resize((self.size, self.size), Image.ANTIALIAS)\n",
    "                img = np.array(img) / 255.0\n",
    "                images.append(img)\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.color_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        color_img = transforms.ToTensor()(self.color_images[idx])\n",
    "        gray_img = transforms.ToTensor()(self.gray_images[idx])\n",
    "        return gray_img, color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef06f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationModel, self).__init__()\n",
    "        # Define your layers here\n",
    "        self.downsample1 = self.downsample(3, 128, kernel_size=3, apply_batch_normalization=False)\n",
    "        self.downsample2 = self.downsample(128, 128, kernel_size=3, apply_batch_normalization=False)\n",
    "        self.downsample3 = self.downsample(128, 256, kernel_size=3, apply_batch_normalization=True)\n",
    "        self.upsample1 = self.upsample(256, 128, kernel_size=3, dropout=False)\n",
    "        self.upsample2 = self.upsample(128, 128, kernel_size=3, dropout=False)\n",
    "        self.upsample3 = self.upsample(128, 3, kernel_size=3, dropout=False)\n",
    "        self.upsample4 = self.upsample(3, 3, kernel_size=2, dropout=False)\n",
    "        self.conv_output = nn.Conv2d(3, 3, kernel_size=3, padding=1).to(torch.double)\n",
    "        self.upsample_output = nn.Upsample((160, 160), mode='bilinear', align_corners=False)\n",
    "\n",
    "    def downsample(self, in_channels, out_channels, kernel_size, apply_batch_normalization=True):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, stride=2).to(torch.float32))\n",
    "        if apply_batch_normalization:\n",
    "            layers.append(nn.BatchNorm2d(out_channels).to(torch.float32))\n",
    "        layers.append(nn.LeakyReLU(0.2).to(torch.float32))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def upsample(self, in_channels, out_channels, kernel_size, dropout=False):\n",
    "        layers = []\n",
    "        layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, padding=1, stride=2, output_padding=1))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.downsample1(x)\n",
    "        d2 = self.downsample2(d1)\n",
    "        d3 = self.downsample3(d2)\n",
    "\n",
    "        u1 = self.upsample1(d3) + d2\n",
    "        u2 = self.upsample2(u1) + d1\n",
    "        u3 = self.upsample3(u2) + x\n",
    "        u4 = self.upsample4(u3)\n",
    "\n",
    "        # Adjust the final convolutional layer to match the target size\n",
    "        conv_output = self.conv_output(u4)\n",
    "        upsample_output = self.upsample_output(conv_output)\n",
    "\n",
    "        return upsample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b434be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/7129 [00:00<?, ?it/s]<ipython-input-11-4324545365c3>:18: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((self.size, self.size), Image.ANTIALIAS)\n",
      " 84%|█████████████████████████████████████████████████████████████████▋            | 6000/7129 [01:03<00:11, 95.22it/s]\n",
      " 32%|█████████████████████████▎                                                    | 2311/7129 [00:24<00:50, 94.65it/s]"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset and model\n",
    "color_dataset = ColorizationDataset(color_path=r'C:\\Users\\ulas_\\OneDrive\\Masaüstü\\Deep Learning Project\\landscape Images\\color',\n",
    "                                    gray_path=r'C:\\Users\\ulas_\\OneDrive\\Masaüstü\\Deep Learning Project\\landscape Images\\gray')\n",
    "\n",
    "train_size = int(0.8 * len(color_dataset))\n",
    "test_size = len(color_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(color_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n",
    "\n",
    "model = ColorizationModel().to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2799e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8385c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputs shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTargets shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, targets\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Inputs shape:\", inputs.shape)\n",
    "print(\"Outputs shape:\", outputs.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4cec74",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m---> 15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert inputs to double precision\n",
    "        inputs = inputs.to(torch.double)\n",
    "        \n",
    "        # Print shapes\n",
    "        print(\"Batch:\", batch_idx + 1)\n",
    "        print(\"Inputs shape:\", inputs.shape)\n",
    "        print(\"Targets shape:\", targets.shape)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    average_loss = total_loss / total_batches\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Batches: {total_batches}, Average Loss: {average_loss}\")\n",
    "\n",
    "# Training completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0508c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_losses = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        test_loss = criterion(outputs, targets)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "print(\"Mean Test Loss:\", np.mean(test_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting colorized images\n",
    "def plot_images(color, grayscale, predicted):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Color Image', color='green', fontsize=20)\n",
    "    plt.imshow(color.permute(1, 2, 0))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Grayscale Image ', color='black', fontsize=20)\n",
    "    plt.imshow(grayscale.permute(1, 2, 0))\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Predicted Image ', color='Red', fontsize=20)\n",
    "    plt.imshow(predicted.permute(1, 2, 0))\n",
    "\n",
    "for i in range(50, 58):\n",
    "    inputs, targets = test_dataset[i]\n",
    "    inputs = inputs.unsqueeze(0)  # Add batch dimension\n",
    "    targets = targets.unsqueeze(0)\n",
    "    predicted = model(inputs)\n",
    "    plot_images(targets, inputs, predicted)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
