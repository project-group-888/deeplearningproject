{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# this notebook is a simple script to scrape images\n",
    "# first we will get images from the website of US Army\n",
    "# then we will get images from adobe\n",
    "def get_soup(url):\n",
    "    \"\"\"\n",
    "    this is a helper function that takes an url and returns a soup object\n",
    "    :param url: the url of the page we want to scrape\n",
    "    :return: a soup object \n",
    "    \"\"\"\n",
    "    res = requests.get(url) # get the html of the page\n",
    "    res.raise_for_status() \n",
    "    soup = BeautifulSoup(res.text, \"html.parser\") # parse the html\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images from https://www.army.mil/yearinphotos/...\n",
      "Done scraping images from 2016!\n",
      "Done scraping images from 2017!\n",
      "Done scraping images from 2018!\n",
      "Done scraping images from 2019!\n",
      "Done scraping images from 2020!\n",
      "Done scraping images from 2021!\n",
      "Done scraping images from 2022!\n",
      "Done scraping images from 2023!\n",
      "Done scraping images!\n"
     ]
    }
   ],
   "source": [
    "# now we will scrape images from https://www.army.mil/yearinphotos/\n",
    "# this is the official website of US Army and there's gallery of images for each year that are licensed under public domain\n",
    "# we will save these images in a folder called army_year_in_photos under images folder\n",
    "url = \"https://www.army.mil/yearinphotos/\"\n",
    "# we will get pictures from years 2016 to 2023 \n",
    "years = [str(year) for year in range(2016, 2024)]\n",
    "import time\n",
    "print(\"Scraping images from https://www.army.mil/yearinphotos/...\")\n",
    "os.makedirs(\"images/army_year_in_photos\", exist_ok=True)\n",
    "count = 0\n",
    "for year in years:\n",
    "    soup = get_soup(url + year)\n",
    "    images = soup.select(\"img[src]\") # select all img tags that have src attribute\n",
    "    for i, image in enumerate(images): # loop through all images and save them\n",
    "        image_url = urljoin(url, image[\"src\"])\n",
    "        image_res = requests.get(image_url)\n",
    "        image_res.raise_for_status() # raise an exception if the image url is not valid\n",
    "        image_file = open(f\"images/army_year_in_photos/army_year_in_photos{year}{i}.jpg\", \"wb\")\n",
    "        for chunk in image_res.iter_content(100000): \n",
    "            image_file.write(chunk)\n",
    "        image_file.close()\n",
    "    print(f\"Done scraping images from {year}!\")\n",
    "\n",
    "print(\"Done scraping images!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# we will scrape images about military, war, army, guns, tanks, aircrafts, soldier\n",
    "# from popular free stock photos website unsplash.com, \n",
    "# this script will download 100 images about every topic and save them in a folder with the same name under images folder\n",
    "\n",
    "def get_soup(url):\n",
    "    \"\"\"\n",
    "    this is a helper function that takes an url and returns a soup object\n",
    "    :param url: the url of the page we want to scrape\n",
    "    :return: a soup object \n",
    "    \"\"\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images from https://stock.adobe.com...\n",
      "Scraping images about military...\n",
      "Done scraping images about military!\n",
      "Scraping images about war...\n",
      "Done scraping images about war!\n",
      "Scraping images about army...\n",
      "Done scraping images about army!\n",
      "Scraping images about gun...\n",
      "Done scraping images about gun!\n",
      "Scraping images about tank...\n",
      "Done scraping images about tank!\n",
      "Scraping images about aircraft...\n",
      "Done scraping images about aircraft!\n",
      "Scraping images about soldier...\n",
      "Done scraping images about soldier!\n",
      "Scraping images about russian army...\n",
      "Done scraping images about russian army!\n",
      "Scraping images about us navy...\n",
      "Done scraping images about us navy!\n",
      "Scraping images about us army...\n",
      "Done scraping images about us army!\n",
      "Scraping images about us air force...\n",
      "Done scraping images about us air force!\n",
      "Scraping images about us marines...\n",
      "Done scraping images about us marines!\n",
      "Scraping images about us coast guard...\n",
      "Done scraping images about us coast guard!\n",
      "Scraping images about us special forces...\n",
      "Done scraping images about us special forces!\n",
      "Scraping images about us navy seals...\n",
      "Done scraping images about us navy seals!\n",
      "Scraping images about chinese army...\n",
      "Done scraping images about chinese army!\n",
      "Scraping images about chinese navy...\n",
      "Done scraping images about chinese navy!\n",
      "Scraping images about chinese air force...\n",
      "Done scraping images about chinese air force!\n",
      "Scraping images about chinese marines...\n",
      "Done scraping images about chinese marines!\n",
      "Scraping images about chinese special forces...\n",
      "Done scraping images about chinese special forces!\n",
      "Scraping images about russian army...\n",
      "Done scraping images about russian army!\n",
      "Scraping images about russian navy...\n",
      "Done scraping images about russian navy!\n",
      "Scraping images about russian air force...\n",
      "Done scraping images about russian air force!\n",
      "Scraping images about russian marines...\n",
      "Done scraping images about russian marines!\n",
      "Scraping images about russian special forces...\n",
      "Done scraping images about russian special forces!\n",
      "Scraping images about turkish army...\n",
      "Done scraping images about turkish army!\n",
      "Scraping images about turkish navy...\n",
      "Done scraping images about turkish navy!\n",
      "Scraping images about turkish air force...\n",
      "Done scraping images about turkish air force!\n",
      "Scraping images about turkish marines...\n",
      "Done scraping images about turkish marines!\n",
      "Scraping images about turkish special forces...\n",
      "Done scraping images about turkish special forces!\n"
     ]
    }
   ],
   "source": [
    "# let's scrape images from adobe stock images\n",
    "# https://stock.adobe.com/search?k={keyword}\n",
    "# we will save these images in a folder called adobe_stock under images folder\n",
    "import os\n",
    "\n",
    "# these keywords are derived with the help of WordsAPI\n",
    "# these are hot words(related) words to military and war\n",
    "keywords = [\"military\", \"war\", \"army\", \"gun\", \"tank\", \"aircraft\", \"soldier\", \"russian army\",\n",
    "             \"us navy\", \"us army\", \"us air force\", \"us marines\", \"us coast guard\", \n",
    "             \"us special forces\", \"us navy seals\", \"chinese army\", \"chinese navy\", \"chinese air force\",\n",
    "             \"chinese marines\", \"chinese special forces\", \"russian army\", \"russian navy\", \n",
    "             \"russian air force\", \"russian marines\", \"russian special forces\",\n",
    "             \"turkish army\", \"turkish navy\", \"turkish air force\", \"turkish marines\", \"turkish special forces\"]\n",
    "print(\"Scraping images from https://stock.adobe.com...\")\n",
    "os.makedirs(\"images/adobe_stock\", exist_ok=True)\n",
    "# for every keyword we will scrape 30 images\n",
    "for keyword in keywords:\n",
    "    print(f\"Scraping images about {keyword}...\")\n",
    "    url = f\"https://stock.adobe.com/search?k={keyword}\"\n",
    "    soup = get_soup(url)\n",
    "    images = soup.select(\"img[src]\") # select all img tags that have src attribute\n",
    "    for i, image in enumerate(images): # loop through all images and save them\n",
    "        if i == 30:\n",
    "            break\n",
    "        image_url = urljoin(url, image[\"src\"])\n",
    "        image_res = requests.get(image_url)\n",
    "        image_res.raise_for_status() # raise an exception if the image url is not valid\n",
    "        image_file = open(f\"images/adobe_stock/{keyword}{i}.jpg\", \"wb\")\n",
    "        for chunk in image_res.iter_content(100000): \n",
    "            image_file.write(chunk)\n",
    "        image_file.close()\n",
    "    print(f\"Done scraping images about {keyword}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images about rifle...\n",
      "Done scraping images about rifle!\n",
      "Scraping images about machine gun...\n",
      "Done scraping images about machine gun!\n",
      "Scraping images about pistol...\n",
      "Done scraping images about pistol!\n",
      "Scraping images about submachine gun...\n",
      "Done scraping images about submachine gun!\n",
      "Scraping images about sniper rifle...\n",
      "Done scraping images about sniper rifle!\n",
      "Scraping images about shotgun...\n",
      "Done scraping images about shotgun!\n",
      "Scraping images about grenade...\n",
      "Done scraping images about grenade!\n",
      "Scraping images about rocket launcher...\n",
      "Done scraping images about rocket launcher!\n",
      "Scraping images about missile...\n",
      "Done scraping images about missile!\n",
      "Scraping images about tank...\n",
      "Done scraping images about tank!\n",
      "Scraping images about fighter jet...\n",
      "Done scraping images about fighter jet!\n",
      "Scraping images about helicopter...\n",
      "Done scraping images about helicopter!\n",
      "Scraping images about bomber...\n",
      "Done scraping images about bomber!\n",
      "Scraping images about aircraft carrier...\n",
      "Done scraping images about aircraft carrier!\n",
      "Scraping images about warship...\n",
      "Done scraping images about warship!\n",
      "Scraping images about submarine...\n",
      "Done scraping images about submarine!\n",
      "Scraping images about general...\n",
      "Done scraping images about general!\n",
      "Scraping images about british army...\n",
      "Done scraping images about british army!\n",
      "Scraping images about british navy...\n",
      "Done scraping images about british navy!\n",
      "Scraping images about british air force...\n",
      "Done scraping images about british air force!\n",
      "Scraping images about british marines...\n",
      "Done scraping images about british marines!\n",
      "Scraping images about british special forces...\n",
      "Done scraping images about british special forces!\n",
      "Scraping images about german army...\n",
      "Done scraping images about german army!\n",
      "Scraping images about german navy...\n",
      "Done scraping images about german navy!\n",
      "Scraping images about german air force...\n",
      "Done scraping images about german air force!\n",
      "Scraping images about german marines...\n",
      "Done scraping images about german marines!\n",
      "Scraping images about german special forces...\n",
      "Done scraping images about german special forces!\n",
      "Done scraping images!\n"
     ]
    }
   ],
   "source": [
    "# same approach with different keywords\n",
    "# we added more keywords to get more images\n",
    "keywords2 = [\"rifle\", \"machine gun\", \"pistol\", \"submachine gun\", \"sniper rifle\", \"shotgun\", \"grenade\", \"rocket launcher\",\n",
    "            \"missile\", \"tank\", \"fighter jet\", \"helicopter\", \"bomber\", \"aircraft carrier\", \"warship\", \"submarine\",\n",
    "            \"general\", \"british army\", \"british navy\", \"british air force\", \"british marines\", \"british special forces\",\n",
    "            \"german army\", \"german navy\", \"german air force\", \"german marines\", \"german special forces\"]\n",
    "for keyword in keywords2:\n",
    "    print(f\"Scraping images about {keyword}...\")\n",
    "    url = f\"https://stock.adobe.com/search?k={keyword}\"\n",
    "    soup = get_soup(url)\n",
    "    images = soup.select(\"img[src]\") # select all img tags that have src attribute\n",
    "    for i, image in enumerate(images): # loop through all images and save them\n",
    "        if i == 30:\n",
    "            break\n",
    "        image_url = urljoin(url, image[\"src\"])\n",
    "        image_res = requests.get(image_url)\n",
    "        image_res.raise_for_status() # raise an exception if the image url is not valid\n",
    "        image_file = open(f\"images/adobe_stock/{keyword}{i}.jpg\", \"wb\")\n",
    "        for chunk in image_res.iter_content(100000): \n",
    "            image_file.write(chunk)\n",
    "        image_file.close()\n",
    "    print(f\"Done scraping images about {keyword}!\")\n",
    "\n",
    "print(\"Done scraping images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After scraping these images\n",
    "#### We need to prepare them for our model\n",
    "#### To do this first we resize them to 160*160 and rename them for convenience\n",
    "#### After all these we create grayscale versions of these images and put them in another folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import shutil\n",
    "# these are helper functions to resize, rename and grayscale images to prepare them for the model\n",
    "def resize_images(source_path, target_path):\n",
    "    \"\"\"\n",
    "    this function resizes all images in source_path to 160x160 and saves them in target_path\n",
    "    args:\n",
    "        source_path: the path of the folder that contains the images\n",
    "        target_path: the path of the folder that will contain the resized images\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_path):\n",
    "        print('No source_path folder found.')\n",
    "        return\n",
    "    if not os.path.exists(target_path): # create the target folder if it doesn't exist\n",
    "        os.mkdir(target_path)\n",
    "    for i, f in enumerate(os.listdir(source_path)):\n",
    "        try:\n",
    "            img = Image.open(source_path + f)\n",
    "            img = img.resize((160, 160), Image.LANCZOS)\n",
    "            img.save(target_path + f)\n",
    "        except:\n",
    "            print('Error resizing image: ' + f)\n",
    "    print('Done.')\n",
    "\n",
    "def rename_images(path):\n",
    "    \"\"\" \n",
    "    this function renames all images in path to 00001.jpg, 00002.jpg, etc.\n",
    "    args:\n",
    "        path: the path of the folder that contains the images\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print('No folder found.')\n",
    "        return\n",
    "    for i, f in enumerate(os.listdir(path)):\n",
    "        shutil.move(path + f, path + str(i + 1).zfill(5) + '.jpg') # rename the image\n",
    "    print('Done.')\n",
    "\n",
    "from PIL import Image\n",
    "def grayscale_images(source_path, target_path):\n",
    "    \"\"\" \n",
    "    this function converts all images in source_path to grayscale and saves them in target_path\n",
    "    args:\n",
    "        source_path: the path of the folder that contains the images\n",
    "        target_path: the path of the folder that will contain the grayscale images\"\"\"\n",
    "    if not os.path.exists(source_path):\n",
    "        print(f'No {source_path} folder found.')\n",
    "        return\n",
    "    if not os.path.exists(target_path):\n",
    "        os.mkdir(target_path)\n",
    "    for i, f in enumerate(os.listdir(source_path)):\n",
    "        try:\n",
    "            img = Image.open(source_path + f).convert('L')\n",
    "            img.save(target_path + f)\n",
    "        except:\n",
    "            print('Error converting image: ' + f)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### resize_images() -> rename_images() -> grayscale_images\n",
    "##### That was our process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
